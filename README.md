# IntuitMapReduce

`You have two CSVs in HDFS. One has customer information <customer_id,name,street,city,state,zip>. The other has sales information <timestamp,customer_id,sales_price> . Write a MapReduce job that uses reduce-side join to produce a CSV in HDFS with <state,total_sales>



Customer

Customer_Id |  Name | Street | City | State | Zip



Sales

Customer_Id | TimeStamp | Sales_Price



1]Mapper Phase

Mapper Stage for Customer

public static class CustomerMapper extends Mapper <Object, Text, Text, Text>
{
public void map(Object key, Text value, Context context) throws IOException, InterruptedException
{String record = value.toString();
String[] parts = record.split(",");
context.write(new Text(parts[0]), new Text("state\t" + parts[4]));   // we need Customer_Id and State column 
}
}

So Mapper Stage for Customer table woulld produce below output

Example: [12345, state   California], [13832, State   Texas], [13832, State   Texas],



Mapper Stage for Sales


public static class TxnsMapper extends Mapper <Object, Text, Text, Text>
{
public void map(Object key, Text value, Context context) throws IOException, InterruptedException
{
String record = value.toString();
String[] parts = record.split(",");
context.write(new Text(parts[0]), new Text("Sales_Price\t" + parts[2]));
}
}

So Mapper Stage for Sales table woulld produce below output


Example: [12345, Sales_Price   500000], [13832, Sales_Price   400000], [13832, Sales_Price   300000]


2] Sorting and Shuffling Phase



The sorting and shuffling phase will generate an array list of values corresponding to each key. In other words, it will put together all the values corresponding to each unique key in the intermediate key-value pair. The output of sorting and shuffling phase will be of the following format:


Key – list of Values:



{California– [ (Sales_Price    400000), (Sales_Price    100000),…]};

{Texas [ (Sales_Price    200000), (Sales_Price    50000),…]};

{New York [ (Sales_Price    800000), (Sales_Price    150000),…]};




3] Reducer Phase

In each of the reducer I will have a key & list of values where key will be states and value will be list of Sales_Prices The list of values will have the input from both the datasets 

Now, I will loop through the values present in the list of values in the reducer

I will perform following steps in reducer while going through all values in list

I will cumulatively update the Sales_Price amount to calculate the total Sales_Price generated by the particular state

public static class ReduceJoinReducer extends Reducer <Text, Text, Text, Text>
{
public void reduce(Text key, Iterable<Text> values, Context context)
throws IOException, InterruptedException 
{

Integer total = 0;

for (Text t : values) 
{ 
String parts[] = t.toString().split("\t");
if (parts[0].equals("Sales_Price")) 
{

total += Integer.parseInt(parts[1]);
} 

}
context.write(new Text(state), new Text(total));
}
}S

so my final output will be 

California  500000 (ie Sum of 400000 and 10000)
Texas   	250000(ie sum of 200000 and 50000)
New York   	950000(ie sum of 800000 and 150000)

